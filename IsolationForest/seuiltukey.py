# ===============================
#  Isolation Forest - D√©tection d‚Äôanomalies
#  Jad Falaq | Projet de d√©tection de transactions manquantes
# ===============================

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve
import seaborn as sns
import matplotlib.pyplot as plt

# --- 1Ô∏è‚É£ Chargement des donn√©es ---
book1 = pd.read_csv('afriware_train.csv', low_memory=False)
book2 = pd.read_csv('final-stage/data/Book2.csv', low_memory=False)
book3 = pd.read_csv('final-stage/data/Book3.csv', low_memory=False)

# --- 2Ô∏è‚É£ Cr√©ation des labels : 1 = transaction manquante ---
book1['in_jde911'] = 1 - book1['NumFacture'].isin(book2['GLDOC']).astype(int)
book1['in_jde311'] = 1 - book1['NumFacture'].isin(book3['RPDOC']).astype(int)

# --- 3Ô∏è‚É£ Nettoyage des dates et types ---
for date_col in ['DateCreation', 'DateModification', 'DateEDI', 'DateFacture']:
    if date_col in book1.columns:
        book1[date_col] = pd.to_datetime(book1[date_col], errors='coerce')

if 'TypeFacture' in book1.columns:
    book1['TypeFacture'] = book1['TypeFacture'].astype(str)

# --- 4Ô∏è‚É£ S√©lection des variables num√©riques ---
X = book1[['CodeClient', 'CompteProduit', 'CentreAnalyse', 'MontantHT', 'MontantTTC', 'Taxes']].apply(pd.to_numeric, errors='coerce').fillna(0)

# --- 5Ô∏è‚É£ Application du mod√®le Isolation Forest ---
iso = IsolationForest(
    n_estimators=200,
    contamination='auto',  # proportion d'anomalies estim√©e automatiquement
    random_state=42
)
iso.fit(X)

# --- 6Ô∏è‚É£ Calcul du score d‚Äôanomalie ---
book1['anomaly_score'] = iso.decision_function(X)
book1['anomaly_flag'] = iso.predict(X)  # -1 = anomalie, 1 = normale
book1['anomaly_flag'] = book1['anomaly_flag'].map({1: 0, -1: 1})  # 1 = anomalie

# --- 7Ô∏è‚É£ Calibration du seuil √† partir des vraies classes ---
y_true = book1['in_jde911'].values  # transactions manquantes (1) ou pr√©sentes (0)
scores_inv = -book1['anomaly_score'].values  # inversion (car bas = anomalie)

precisions, recalls, thresholds = precision_recall_curve(y_true, scores_inv)
f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)
best_idx = np.argmax(f1_scores)
best_thresh = thresholds[best_idx]

print(f"\n‚úÖ Seuil optimis√© (bas√© sur F1-score) = {best_thresh:.5f}")
print(f"‚Üí Pr√©cision : {precisions[best_idx]:.3f} | Rappel : {recalls[best_idx]:.3f} | F1-score : {f1_scores[best_idx]:.3f}")

# --- 8Ô∏è‚É£ Classification selon le seuil optimis√© ---
book1['predicted_anomaly'] = (scores_inv >= best_thresh).astype(int)

# --- 9Ô∏è‚É£ √âvaluation du mod√®le ---
print("\n=== Rapport de classification Isolation Forest (seuil optimis√©) ===")
print(classification_report(y_true, book1['predicted_anomaly']))

cm = confusion_matrix(y_true, book1['predicted_anomaly'])
print("\nMatrice de confusion :\n", cm)

# --- üîü Visualisation ---
sns.boxplot(x=y_true, y=book1['anomaly_score'])
plt.axhline(y=-best_thresh, color='r', linestyle='--', label='Seuil optimis√©')
plt.title("Isolation Forest - Score d'anomalie par classe r√©elle")
plt.xlabel("Classe r√©elle (0 = pr√©sente, 1 = manquante)")
plt.ylabel("Score d'anomalie")
plt.legend()
plt.show()

# --- 11Ô∏è‚É£ Sauvegarde des r√©sultats ---
book1[['NumFacture', 'in_jde911', 'anomaly_score', 'predicted_anomaly']].to_csv('IsolationForest_results.csv', index=False)
print("\nüíæ Fichier des r√©sultats sauvegard√© : IsolationForest_results.csv")
